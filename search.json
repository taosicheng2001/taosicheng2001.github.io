[{"title":"NOC: Researches on Cache Coherency NOC Router and Flow Control","url":"/2024/07/16/NOC-Researches-on-Cache-Coherency-NOC-Router-and-Flow-Control/","content":"\n# Further Reading\nDuato 自适应算法无死锁[167, 204, 205]\n基于切片的虫孔交换[170]\n\n# Chapter 3\n多程序运行在同一众核平台上，引入了负载整合工作模式（多个核心划分为多个区域，每个程序使用其中一个区域）\n\n多个应用程序的隔离+有效共享片上资源\n\n提供足够的适应性解决拥塞，不利用冗余的网络状态信息，动态隔离多个程序\n\n自适应路由=路由函数+选择策略\n\n应用程序内部的干扰+应用程序之间的干扰 => 当前位置和目标节点确定的区域外的所有路由都不应该被进入网络状态信息统计\n\n拥塞信息传播网络 => 西侧和本地的东输入端口状态传递给东侧，其他方向和维度同理。\n\n指标计算SMC 维度预选择DP 路由计算RC 虚通道分配VA 交叉开关分配SA 交叉开关传输ST 链路传输LT\nSMC 考察congestion_X和congestion_Y的相对大小，以确定cur节点到pos节点的out_dim选择\n\n# Chapter 4\n路由算法要求无死锁 网络层死锁 or 协议层死锁\n\n128位flit宽度下 一致性控制消息只需要1flit编码即可(且占比高78.7%) Cache行数据消息需要5flit编码\n\n片上连线资源丰富，但缓存资源紧缺\n\nWPF(whole packet forwarding): 如果一条非空虚通道有足够的空闲缓存来接收整个报文，则允许非空虚通道被重新分配\n","tags":["Paper Reading"],"categories":["Computer Architecture","Network On Chip"]},{"title":"Hello World","url":"/2024/05/05/hello-world/","content":"Welcome to [Hexo](https://hexo.io/)! This is your very first post. Check [documentation](https://hexo.io/docs/) for more info. If you get any problems when using Hexo, you can find the answer in [troubleshooting](https://hexo.io/docs/troubleshooting.html) or you can ask me on [GitHub](https://github.com/hexojs/hexo/issues).\n\n## Quick Start\n\n### Create a new post\n\n``` bash\n$ hexo new \"My New Post\"\n```\n\nMore info: [Writing](https://hexo.io/docs/writing.html)\n\n### Run server\n\n``` bash\n$ hexo server\n```\n\nMore info: [Server](https://hexo.io/docs/server.html)\n\n### Generate static files\n\n``` bash\n$ hexo generate\n```\n\nMore info: [Generating](https://hexo.io/docs/generating.html)\n\n### Deploy to remote sites\n\n``` bash\n$ hexo deploy\n```\n$\\sqrt{3x-1}+(1+x)^2$\n\nMore info: [Deployment](https://hexo.io/docs/one-command-deployment.html)\n"},{"title":"RISCV-BOOM(3)","url":"/2024/04/11/RISCV-BOOM-3/","content":"# RISCV-BOOM ICACHE\n\n在RISCV-BOOM(2)中，我们对BOOM的前端代码(`frontend.scala`)进行了简要分析，发现除了F3内针对`fetch_bundle`的处理外，其余部分都在作为顶层模组，完成对各个子模组的连接。所以要真正理解前端的各种实现，我们还需要对各个子模组进行分析和理解。本文针对ICache进行分析，其代码为`icache.scala`。\n\n## 代码分析\n\n### `ICache`\n包装了`ICache Module`实例化的类，通过调整传入参数`icacheParams`可进行快速配置。在实例化`ICacheModule`的同时，也设置了`masterNode`，这是片上互联的一种节点。\n```scala\n/**\n * ICache module\n *\n * @param icacheParams parameters for the icache\n * @param hartId the id of the hardware thread in the cache\n * @param enableBlackBox use a blackbox icache\n */\nclass ICache(\n  val icacheParams: ICacheParams,\n  val staticIdForMetadataUseOnly: Int)(implicit p: Parameters)\n  extends LazyModule\n{\n  lazy val module = new ICacheModule(this)\n  val masterNode = TLClientNode(Seq(TLMasterPortParameters.v1(Seq(TLMasterParameters.v1(\n    sourceId = IdRange(0, 1 + icacheParams.prefetch.toInt), // 0=refill, 1=hint\n    name = s\"Core ${staticIdForMetadataUseOnly} ICache\")))))\n\n  val size = icacheParams.nSets * icacheParams.nWays * icacheParams.blockBytes\n  private val wordBytes = icacheParams.fetchBytes\n}\n```\n\n### `ICacheResp`\n离开ICache的IO信号(ICache返回到Frontend的信号)\n```scala\nclass ICacheResp(val outer: ICache) extends Bundle\n{\n  val data = UInt((outer.icacheParams.fetchBytes*8).W)\n  val replay = Bool()\n  val ae = Bool() // Access Exception\n}\n```\n\n\n### `ICache Bundle`\n```scala\nclass ICacheBundle(val outer: ICache) extends BoomBundle()(outer.p)\n  with HasBoomFrontendParameters\n{\n  val req = Flipped(Decoupled(new ICacheReq)) // Decoupled是生产者——消费者数据传输模型接口，具有valid, bits. ready这三个信号。 这个接口是站在数据传输者的角度定义数据传输方向的\n  // Flipped将该数据传输方向翻转\n  // 两者结合后，该数据传输方向为外到内\n  val s1_paddr = Input(UInt(paddrBits.W)) // delayed one cycle w.r.t. req\n\n  val s1_kill = Input(Bool()) // delayed one cycle w.r.t. req\n  val s2_kill = Input(Bool()) // delayed two cycles; prevents I$ miss emission\n\n  val resp = Valid(new ICacheResp(outer)) // Valid会生成一个新Bundle,带有valid和bits这两个信号\n  val invalidate = Input(Bool())\n\n  val perf = Output(new Bundle {\n    val acquire = Bool()\n  })\n}\n```\n\n### `ICacheModule`\n实际实现功能的类，定义了ICache内部信号的生成和传输。\n```scala\nclass ICacheModule(outer: ICache) extends LazyModuleImp(outer)\n  with HasBoomFrontendParameters\n{\n  val enableICacheDelay = tileParams.core.asInstanceOf[BoomCoreParams].enableICacheDelay\n  val io = IO(new ICacheBundle(outer))\n  val (tl_out, edge_out) = outer.masterNode.out(0)\n\n  require(isPow2(nSets) && isPow2(nWays))\n  require(usingVM)\n  require(pgIdxBits >= untagBits)\n\n  // How many bits do we intend to fetch at most every cycle?\n  val wordBits = outer.icacheParams.fetchBytes*8  // fetchBytes = 8\n  // Each of these cases require some special-case handling.\n  require (tl_out.d.bits.data.getWidth == wordBits || (2*tl_out.d.bits.data.getWidth == wordBits && nBanks == 2))\n  // If TL refill is half the wordBits size and we have two banks, then the\n  // refill writes to only one bank per cycle (instead of across two banks every\n  // cycle).\n  val refillsToOneBank = (2*tl_out.d.bits.data.getWidth == wordBits)\n  \n  // nWays = 4; nSets = 64\n\n  val s0_valid = io.req.fire // fire信号是valid & ready, 来自frontend的fire \n  val s0_vaddr = io.req.bits.addr // 传入VA\n\n  val s1_valid = RegNext(s0_valid)\n  val s1_tag_hit = Wire(Vec(nWays, Bool()))\n  val s1_hit = s1_tag_hit.reduce(_||_)\n  val s2_valid = RegNext(s1_valid && !io.s1_kill)\n  val s2_hit = RegNext(s1_hit)\n\n\n  val invalidated = Reg(Bool())\n  val refill_valid = RegInit(false.B)\n  val refill_fire = tl_out.a.fire\n  val s2_miss = s2_valid && !s2_hit && !RegNext(refill_valid)\n\n  // Refill Sign\n  val refill_paddr = RegEnable(io.s1_paddr, s1_valid && !(refill_valid || s2_miss)) // RegEnable(nextVal, ena)\n  // untagBits = blockOffBits + idxBits\n  val refill_tag = refill_paddr(tagBits+untagBits-1,untagBits)\n  val refill_idx = refill_paddr(untagBits-1,blockOffBits)\n  val refill_one_beat = tl_out.d.fire && edge_out.hasData(tl_out.d.bits) // 通过TileLink节点连接下层存储\n\n  io.req.ready := !refill_one_beat // ready的前提是没有refill_one_beat\n\n  val (_, _, d_done, refill_cnt) = edge_out.count(tl_out.d)\n  val refill_done = refill_one_beat && d_done\n  tl_out.d.ready := true.B\n  require (edge_out.manager.minLatency > 0)\n\n  val repl_way = if (isDM) 0.U else LFSR(16, refill_fire)(log2Ceil(nWays)-1,0) // Replace_Way;  LFSR(width, increment_Ena) 产生随机数\n\n  /*\n        way0  ...   way15\n    |---------|---------|  set0 \n    |---------|---------|  set1\n    |---------|---------|  ...\n    |---------|---------|  set63\n    |-------------------|  \n\n  */\n  val tag_array = SyncReadMem(nSets, Vec(nWays, UInt(tagBits.W))) // 存储Tag的阵列,SyncReadMem(sizeNumber, dataType), Vec(sizeNumber, dataType)\n  val tag_rdata = tag_array.read(s0_vaddr(untagBits-1, blockOffBits), !refill_done && s0_valid) // 用index索引set去读Tag_array,得到nWay个Tag； 函数调用read(index, ena)\n  when (refill_done) {\n    tag_array.write(refill_idx, VecInit(Seq.fill(nWays)(refill_tag)), Seq.tabulate(nWays)(repl_way === _.U)) \n    // 函数调用 write(index, data, mask) \n    // 函数调用 Seq.fill(number)(genElement) \n    // 函数调用 Seq.tabulate(number)(genFunc)\n  }\n\n  val vb_array = RegInit(0.U((nSets*nWays).W)) // valid_bit_array\n  when (refill_one_beat) {\n    vb_array := vb_array.bitSet(Cat(repl_way, refill_idx), refill_done && !invalidated)\n    // 函数调用 bitSet(index, bool_value)\n  }\n\n  when (io.invalidate) {\n    vb_array := 0.U\n    invalidated := true.B\n  }\n\n  val s2_dout   = Wire(Vec(nWays, UInt(wordBits.W)))\n  val s1_bankid = Wire(Bool())\n\n  // 计算tag_hit\n  for (i <- 0 until nWays) {\n    val s1_idx = io.s1_paddr(untagBits-1,blockOffBits) // 感觉这个s1_idx没啥必要\n    val s1_tag = io.s1_paddr(tagBits+untagBits-1,untagBits)\n    val s1_vb = vb_array(Cat(i.U, s1_idx))\n    val tag = tag_rdata(i)\n    s1_tag_hit(i) := s1_vb && tag === s1_tag\n  }\n  assert(PopCount(s1_tag_hit) <= 1.U || !s1_valid) // 最多只有一路命中\n\n\n  // 这里还考虑了refill的周期数，利用refill_cnt把不同cnt下的值都保存\n  val ramDepth = if (refillsToOneBank && nBanks == 2) {\n    nSets * refillCycles / 2\n  } else {\n    nSets * refillCycles\n  }\n\n  // dataArrays[wayIndex][setIndex]\n  val dataArrays = if (nBanks == 1) {\n    // Use unbanked icache for narrow accesses.\n    // 这里的dataArray是具有nWays个元素的map，每个元素是一个SyncReadMem，深度为wordBits\n    (0 until nWays).map { x =>\n      DescribedSRAM(\n        name = s\"dataArrayWay_${x}\",\n        desc = \"ICache Data Array\",\n        size = ramDepth,\n        data = UInt((wordBits).W)\n      )\n    }\n  } else {\n    // Use two banks, interleaved. 分双bank,多体交叉编址\n    // 这里的dataArray是具有nWays+nWays个元素的map，每个元素是一个SyncReadMem，深度为wordBits/nBanks\n\n    (0 until nWays).map { x =>\n      DescribedSRAM(\n        name = s\"dataArrayB0Way_${x}\",\n        desc = \"ICache Data Array\",\n        size = ramDepth,\n        data = UInt((wordBits/nBanks).W)\n      )} ++\n    (0 until nWays).map { x =>\n      DescribedSRAM(\n        name = s\"dataArrayB1Way_${x}\",\n        desc = \"ICache Data Array\",\n        size = ramDepth,\n        data = UInt((wordBits/nBanks).W)\n      )}\n  }\n    \n  /*  \n      MSB                                    LSB\n       [ tagBits ][ indexBits ][ blockOffBits ] paddr，传入Icache的物理地址\n                  [ indexBits ]                 refill_idx对应的字段\n        [ indexBits ][  lgRC  ][ blockOffBits ] 不分Bank的dataArrays[x_Ways]的寻址模式，这里的lgRC是log2Ceil(refillCycles);\n                  [     row    [  lgRC  ]]      不分bank下row对应的字段(截取vaddr)\n          [ indexBits ][lgRC-1][ blockOffBits ] 分Bank的dataArraysBx[x_Ways] 里面的寻址模式;整体容量小了一半\n                  [    b0row   [lgRC-1]]        分bank下bxrow(refillsToOneBank)对应的字段(截取vaddr)\n                  [   b0row    [  lgRC  ]]      分bank下bxrow(!refillsToOneBank)对应的字段(截取vaddr)\n  */\n\n  if (nBanks == 1) {\n    // Use unbanked icache for narrow accesses.\n    s1_bankid := 0.U\n    for ((dataArray, i) <- dataArrays.zipWithIndex) {\n      // 函数调用 zipWithIndex 返回列表元素和其下标 [(ele0, 0), (ele1, 1), ..., (elen, n)]\n      // 这里返回nWays个元素，每个元素是一个SyncReadMem\n      def row(addr: UInt) = addr(untagBits-1, blockOffBits-log2Ceil(refillCycles))\n      val s0_ren = s0_valid\n\n      val wen = (refill_one_beat && !invalidated) && repl_way === i.U\n\n      val mem_idx = Mux(refill_one_beat, (refill_idx << log2Ceil(refillCycles)) | refill_cnt,\n                    row(s0_vaddr))\n      // refill_idx 用的是paddr\n      // s0_vaddr   用的是vaddr\n\n      when (wen) {\n        dataArray.write(mem_idx, tl_out.d.bits.data)\n      }\n      if (enableICacheDelay)\n        s2_dout(i) := dataArray.read(RegNext(mem_idx), RegNext(!wen && s0_ren)) // 下一拍才读dataArray\n      else\n        s2_dout(i) := RegNext(dataArray.read(mem_idx, !wen && s0_ren)) // 这一拍读dataArray,下一拍送出来\n    }\n  } else {\n    // Use two banks, interleaved.\n\n    val dataArraysB0 = dataArrays.take(nWays) // 取出前面nWays个元素放入新Map\n    val dataArraysB1 = dataArrays.drop(nWays) // 把前面nWays个元素删除，留下后nWays个元素\n    require (nBanks == 2)\n\n    // Bank0 row's id wraps around if Bank1 is the starting bank.\n    def b0Row(addr: UInt) =\n      if (refillsToOneBank) {\n        addr(untagBits-1, blockOffBits-log2Ceil(refillCycles)+1) + bank(addr)\n      } else {\n        addr(untagBits-1, blockOffBits-log2Ceil(refillCycles)) + bank(addr)\n      }\n    // Bank1 row's id stays the same regardless of which Bank has the fetch address.\n    def b1Row(addr: UInt) =\n      if (refillsToOneBank) {\n        addr(untagBits-1, blockOffBits-log2Ceil(refillCycles)+1)\n      } else {\n        addr(untagBits-1, blockOffBits-log2Ceil(refillCycles))\n      }\n\n    s1_bankid := RegNext(bank(s0_vaddr))\n\n    for (i <- 0 until nWays) {\n      \n      // [ tagBits ][ indexBits ][ blockOffBits ] paddr，传入Icache的物理地址\n      //    [ indexBits ][lgRC-1][ blockOffBits ] 分Bank的dataArraysBx[x_Ways] 里面的寻址模式\n      //  [ indexBits ][ lgRC ]                   refill_idx << log2Ceil(refillCycles) | refill_cnt对应的字段\n      \n      val s0_ren = s0_valid\n      val wen = (refill_one_beat && !invalidated)&& repl_way === i.U\n\n      var mem_idx0: UInt = null\n      var mem_idx1: UInt = null\n\n      if (refillsToOneBank) {\n        // write a refill beat across only one beat.\n        mem_idx0 =\n          Mux(refill_one_beat, (refill_idx << (log2Ceil(refillCycles)-1)) | (refill_cnt >> 1.U),\n          b0Row(s0_vaddr))\n        mem_idx1 =\n          Mux(refill_one_beat, (refill_idx << (log2Ceil(refillCycles)-1)) | (refill_cnt >> 1.U),\n          b1Row(s0_vaddr))\n\n        // cnt最低位指定使用哪一个bank\n        when (wen && refill_cnt(0) === 0.U) {\n          dataArraysB0(i).write(mem_idx0, tl_out.d.bits.data)\n        }\n        when (wen && refill_cnt(0) === 1.U) {\n          dataArraysB1(i).write(mem_idx1, tl_out.d.bits.data)\n        }\n      } else {\n        // write a refill beat across both banks.\n        // 此时refill_idx的最高位被截断\n\n        mem_idx0 =\n          Mux(refill_one_beat, (refill_idx << log2Ceil(refillCycles)) | refill_cnt,\n          b0Row(s0_vaddr))\n        mem_idx1 =\n          Mux(refill_one_beat, (refill_idx << log2Ceil(refillCycles)) | refill_cnt,\n          b1Row(s0_vaddr))\n\n        when (wen) {\n          val data = tl_out.d.bits.data\n          dataArraysB0(i).write(mem_idx0, data(wordBits/2-1, 0))\n          dataArraysB1(i).write(mem_idx1, data(wordBits-1, wordBits/2))\n        }\n      }\n      if (enableICacheDelay) {\n        s2_dout(i) := Cat(dataArraysB1(i).read(RegNext(mem_idx1), RegNext(!wen && s0_ren)),\n                          dataArraysB0(i).read(RegNext(mem_idx0), RegNext(!wen && s0_ren)))\n      } else {\n        s2_dout(i) := RegNext(Cat(dataArraysB1(i).read(mem_idx1, !wen && s0_ren),\n                                  dataArraysB0(i).read(mem_idx0, !wen && s0_ren)))\n      }\n    }\n  }\n  val s2_tag_hit = RegNext(s1_tag_hit)\n  val s2_hit_way = OHToUInt(s2_tag_hit) // One-hot Vec to UInt\n  val s2_bankid = RegNext(s1_bankid)\n  val s2_way_mux = Mux1H(s2_tag_hit, s2_dout) // Mux select valid dout\n\n  val s2_unbanked_data = s2_way_mux\n  val sz = s2_way_mux.getWidth\n  val s2_bank0_data = s2_way_mux(sz/2-1,0)\n  val s2_bank1_data = s2_way_mux(sz-1,sz/2)\n\n  // 调整顺序，拼接出返回值\n  val s2_data =\n    if (nBanks == 2) {\n      Mux(s2_bankid,\n        Cat(s2_bank0_data, s2_bank1_data),\n        Cat(s2_bank1_data, s2_bank0_data))\n    } else {\n      s2_unbanked_data\n    }\n\n  io.resp.bits.ae := DontCare\n  io.resp.bits.replay := DontCare\n  io.resp.bits.data := s2_data\n  io.resp.valid := s2_valid && s2_hit\n\n  tl_out.a.valid := s2_miss && !refill_valid && !io.s2_kill\n  tl_out.a.bits := edge_out.Get(\n    fromSource = 0.U,\n    toAddress = (refill_paddr >> blockOffBits) << blockOffBits,\n    lgSize = lgCacheBlockBytes.U)._2\n  tl_out.b.ready := true.B\n  tl_out.c.valid := false.B\n  tl_out.e.valid := false.B\n\n  io.perf.acquire := tl_out.a.fire\n\n  when (!refill_valid) { invalidated := false.B } // refill_valid 则 invalidated\n  when (refill_fire) { refill_valid := true.B }   // refill_fire 则 refill_valid\n  when (refill_done) { refill_valid := false.B }  // refill_done 则 !refill_valid\n```\n\n## Sub-Banking and interleaving\nSub-Banking(Multi-Banking)设计最早用于减少能耗，将`data memory array`分解为多个独立的bank，原来需要访问一个BlockSize大小的数据，现在只需要访问BlockSize/nBank大小的数据，能耗降低为原来的1/nBank。架构图如下所示:\n![](/images/sub-Banking.png)\n在此基础上，在Multi-Bank的Cache上进行交叉编址，就可以实现对外提供多端口的Multi-port Cache(MB)。如果划分为C个bank,那么这样设计的Cache可以对外同时提供C次命中，从而提高了Cache的带宽。因为对于处理器而言，这些Cache Bank是同步可见的，对这些Cache Bank的读操作也是同步的。这意味着在一个周期内，处理器可以用多个读操作去同时访问这些Bank内的Cache Line。这种实现被称为水平交叠。\n![horizontal interleaving](/images/horizontal-interleaving.png)\nCache Line interleaving 的根本问题是：在Multi-Banking的Cache上，每个CacheLine(CacheBlock)放置在哪一个Bank内？假设地址的`Index`为$N$位，那么在未分Bank的Cache设计中，共有$L=2^N$个CacheLine。我们有多种切分Bank的方法，分别如b,c,d所示。\n1. ( b )图，按Index的最高位(Index[N-1])进行分割。此时Index[N-1]决定使用哪一个Bank，Index[N-2,0]在Bank内进行索引。在这种分Bank设计下，除了4个边界CacheLine，Index为X的CacheLine在同一个Bank中与Indedx为X+1,X-1的CacheLine相邻。\n2. ( c )图，按Index的最低位(Index[0])进行分割。此时Index[0]决定使用哪一个Bank，Inde[N-1,1]在Bank内进行索引。在这种分Bank设计下，Index为X的CacheLinie和Index为X+1,X-1的CacheLine一定位于不同的两个Bank上。\n3. ( d )图，按Index[1]进行分割。分析类似，省略。\n我们把第2种交叉编制方案( c )图称为垂直交叠\n![Interleaving](/images/Interleaving.png)\n\n## 总结\nBOOM的ICache采用了分Bank技术（也可以配置为不分Bank），目前的框架只支持分为2个Bank。在该ICache的设计中，在TL refill的时候，不同refill_cnt会保存到不同的dataArray地址处，Refill的机制需要在TlieLink中学习。其次，在寻址Mem_idx的时候，同时使用到了vaddr和paddr,这一部分内容需要在TLB中学习。最让人迷惑的就是Mem_idx的生成，由于其牵扯到Refill机制和虚实地址，需要了解这两部分的内容后再进行理解。\n\n**以上です。**\n","tags":["Code Reading"],"categories":["Computer Architecture","RISCV-BOOM"]},{"title":"RISCV-BOOM(2)","url":"/2024/04/07/RISCV-BOOM-2/","content":"# RISCV-BOOM Front-End\n![BOOM Front-End](/images/front-end.svg)\n整体代码位于`src/main/scala/ifu`，其中`frontend.scale`为最顶层，`icache.scala`实现指令缓存，`fetch-buffer.scala`实现取指缓冲区，`fetch-target-queue.scala`干啥呢？,`bpd`目录下的文件实现分支预测\n\n## 代码阅读\n首先从最顶层入手，在`BoomFrontend`类中实例化了前端的所有部件，下面进行一层一层的分析\n```scala\nclass BoomFrontend(val icacheParams: ICacheParams, staticIdForMetadataUseOnly: Int)(implicit p: Parameters) extends LazyModule\n{\n  lazy val module = new BoomFrontendModule(this) // 实例化Module，传入当前BoomFrontend实例作为参数\n  val icache = LazyModule(new boom.ifu.ICache(icacheParams, staticIdForMetadataUseOnly)) // 实例化Icache\n  val masterNode = icache.masterNode // 实例化 Icache的MasterNode\n  val resetVectorSinkNode = BundleBridgeSink[UInt](Some(() =>\n    UInt(masterNode.edges.out.head.bundle.addressBits.W))) // 实例化resetVectorSinkNode\n}\n```\n### `BoomFrontendModule`\n`module`通过`BoomFrontendModule`接口进行实例化，该模块处理了IO连线和前端的五段流水，我们一步步进行分析\n\n#### IO连线\n```scala\n  val io = IO(new BoomFrontendBundle(outer))\n  val io_reset_vector = outer.resetVectorSinkNode.bundle\n  implicit val edge = outer.masterNode.edges.out(0)\n  require(fetchWidth*coreInstBytes == outer.icacheParams.fetchBytes)\n\n  val bpd = Module(new BranchPredictor)\n  bpd.io.f3_fire := false.B\n  val ras = Module(new BoomRAS)\n\n  val icache = outer.icache.module\n  icache.io.invalidate := io.cpu.flush_icache\n  val tlb = Module(new TLB(true, log2Ceil(fetchBytes), TLBConfig(nTLBSets, nTLBWays)))\n  io.ptw <> tlb.io.ptw\n  io.cpu.perf.tlbMiss := io.ptw.req.fire\n  io.cpu.perf.acquire := icache.io.perf.acquire\n```\n首先实例化的是`BoomFrontendBundle`这一IO变量，这个IO包含`BoomFrontedIO`和`TLBPTWIO`。`BoomFrontedIO`是前端和CPU之间的通信IO；`TLBPTWIO`是TLB和PTW之间的通信IO，涉及CPU虚拟地址向物理地址转化的过程。`BranchPredictor()`和`BoomRAS()`分别实例化分支预测器和返回值栈，`icache`在前面已经实例化过，这里直接引用，`TLB()`实例化快表。\n\n#### F0 (NextPC Select)\n前端流水的第一个阶段，主要任务是向ICache发起取指请求。\n```scala\n  // Stage0 初始化所有信号，基本都设置为0\n  val s0_vpc       = WireInit(0.U(vaddrBitsExtended.W))  // Virtual Program Counter\n  val s0_ghist     = WireInit((0.U).asTypeOf(new GlobalHistory)) // Global History \n  val s0_tsrc      = WireInit(0.U(BSRC_SZ.W)) // \"tsrc provides the prediction TO this packet\" \n  val s0_valid     = WireInit(false.B) // 合法标志位 默认为false\n  val s0_is_replay = WireInit(false.B) // 重播标志位 默认为false\n  val s0_is_sfence = WireInit(false.B) // sfence标志位 默认为false\n  val s0_replay_resp = Wire(new TLBResp) \n  val s0_replay_bpd_resp = Wire(new BranchPredictionBundle)\n  val s0_replay_ppc  = Wire(UInt())\n  val s0_s1_use_f3_bpd_resp = WireInit(false.B)\n\n  when (RegNext(reset.asBool) && !reset.asBool) { \n    // 声明一个寄存器，将reset作为寄存器的输入信号，reset应当是一个全局的复位信号\n    // 当reset信号上一个周期为真且当前周期为假时执行该代码段\n    \n    s0_valid   := true.B\n    s0_vpc     := io_reset_vector // 把vpc复位到特定值\n    s0_ghist   := (0.U).asTypeOf(new GlobalHistory)\n    s0_tsrc    := BSRC_C // 设置为 core branch resolution 状态\n  }\n\n  // 向icache传入当前有效标志位和vpc\n  icache.io.req.valid     := s0_valid\n  icache.io.req.bits.addr := s0_vpc\n  \n  // 向bpd传入当前有效标志位，vpc和全局历史记录\n  bpd.io.f0_req.valid      := s0_valid\n  bpd.io.f0_req.bits.pc    := s0_vpc\n  bpd.io.f0_req.bits.ghist := s0_ghist\n```\n\n#### F1 (ICache Access)\n前端流水的第二个阶段，主要任务是(1)利用vpc访问TLB,获取ppc (2)利用ppc访问ICache (3)利用bpd Resp计算出是否重定向以及下一个取指的vpc (4)更新流水段的时序逻辑信号\n```scala\n  // 把上一阶段的寄存器值传递到这一阶段的寄存器中\n  val s1_vpc       = RegNext(s0_vpc)\n  val s1_valid     = RegNext(s0_valid, false.B) // 默认初始值为false\n  val s1_ghist     = RegNext(s0_ghist)\n  val s1_is_replay = RegNext(s0_is_replay)\n  val s1_is_sfence = RegNext(s0_is_sfence)\n  val f1_clear     = WireInit(false.B) \n  val s1_tsrc      = RegNext(s0_tsrc)\n\n  // 访问tlb\n  tlb.io.req.valid      := (s1_valid && !s1_is_replay && !f1_clear) || s1_is_sfence // 生成tlb有效标志位\n  tlb.io.req.bits.cmd   := DontCare\n  tlb.io.req.bits.vaddr := s1_vpc      // 把s1_vpc传给tlb\n  tlb.io.req.bits.passthrough := false.B // 默认不passthrough\n  tlb.io.req.bits.size  := log2Ceil(coreInstBytes * fetchWidth).U\n  tlb.io.req.bits.v     := io.ptw.status.v\n  tlb.io.req.bits.prv   := io.ptw.status.prv\n  tlb.io.sfence         := RegNext(io.cpu.sfence)\n  tlb.io.kill           := false.B // 默认不kill\n\n  // tlb resp\n  val s1_tlb_miss = !s1_is_replay && tlb.io.resp.miss\n  val s1_tlb_resp = Mux(s1_is_replay, RegNext(s0_replay_resp), tlb.io.resp) // 如果s1需要重播,使用s0阶段的重播resp，否则使用tlb的resp\n  val s1_ppc  = Mux(s1_is_replay, RegNext(s0_replay_ppc), tlb.io.resp.paddr) // 如果s1需要重播,使用s0阶段的重播ppc，否则使用tlb的paddr\n  // bpd resp\n  val s1_bpd_resp = bpd.io.resp.f1 // 获取bpd的resp,后续使用resp进行重定向判断\n\n  // 向icache传入tlb翻译后的physical pc和kill标志位\n  icache.io.s1_paddr := s1_ppc\n  icache.io.s1_kill  := tlb.io.resp.miss || f1_clear // 当f1_clear或tlb返回miss时kill\n\n  val f1_mask = fetchMask(s1_vpc) // 若fetchWidth为1,则mask为全1\n  val f1_redirects = (0 until fetchWidth) map { i =>\n    s1_valid && f1_mask(i) && s1_bpd_resp.preds(i).predicted_pc.valid &&\n    (s1_bpd_resp.preds(i).is_jal ||\n      (s1_bpd_resp.preds(i).is_br && s1_bpd_resp.preds(i).taken))\n  } // 生成一个重定向标志位列表，对每个取指的指令检查 取掩码后是否合法，分支预测的PC是否合法，分支预测的指令是否是无条件跳转或Taken的有条件跳转\n  val f1_redirect_idx = PriorityEncoder(f1_redirects) // 选择出重定向标志位列表中最先的1,这个idx指向最早的一个分支重定向指令\n  val f1_do_redirect = f1_redirects.reduce(_||_) && useBPD.B // 归约重定向标志位列表，判断是否需要重定向\n  val f1_targs = s1_bpd_resp.preds.map(_.predicted_pc.bits) // 将predicted_pc成员的bits取出来组成target列表\n  val f1_predicted_target = Mux(f1_do_redirect,\n                                f1_targs(f1_redirect_idx),\n                                nextFetch(s1_vpc))  // 生成下一个取指目标，跳转or顺序\n\n  // 更新GlobalHistory 方法参数分别为 branches, cfi_taken, cfi_is_br, cfi_idx, cfi_valid, addr, cfi_is_call, cfi_is_ret \n  val f1_predicted_ghist = s1_ghist.update(\n    s1_bpd_resp.preds.map(p => p.is_br && p.predicted_pc.valid).asUInt & f1_mask,  //branches 生成分支标志位列表\n    s1_bpd_resp.preds(f1_redirect_idx).taken && f1_do_redirect,    // cfi_taken\n    s1_bpd_resp.preds(f1_redirect_idx).is_br,  // cfi_is_br\n    f1_redirect_idx, // cfi_idx\n    f1_do_redirect, // cfi_valid\n    s1_vpc, // addr\n    false.B, // cfi_is_call\n    false.B) // cfi_is_ret\n\n  when (s1_valid && !s1_tlb_miss) { // 设置s0信号，配合RegNext函数，这些值将在下一个时钟周期有效\n    // Stop fetching on fault\n    s0_valid     := !(s1_tlb_resp.ae.inst || s1_tlb_resp.pf.inst)\n    s0_tsrc      := BSRC_1\n    s0_vpc       := f1_predicted_target // 使用分支预测的结果\n    s0_ghist     := f1_predicted_ghist  // 更新分支预测全局历史\n    s0_is_replay := false.B\n  }\n```\n\n#### F2 (ICache Response)\n\n```scala\n  val s2_valid = RegNext(s1_valid && !f1_clear, false.B) // 默认非Valid，等待置起为有效\n  val s2_vpc   = RegNext(s1_vpc)\n  val s2_ghist = Reg(new GlobalHistory)\n  s2_ghist := s1_ghist\n  val s2_ppc  = RegNext(s1_ppc)\n  val s2_tsrc = RegNext(s1_tsrc) // tsrc provides the predictor component which provided the prediction TO this instruction\n  val s2_fsrc = WireInit(BSRC_1) // fsrc provides the predictor component which provided the prediction FROM this instruction\n  val f2_clear = WireInit(false.B)\n  val s2_tlb_resp = RegNext(s1_tlb_resp)\n  val s2_tlb_miss = RegNext(s1_tlb_miss)\n  val s2_is_replay = RegNext(s1_is_replay) && s2_valid\n  val s2_xcpt = s2_valid && (s2_tlb_resp.ae.inst || s2_tlb_resp.pf.inst) && !s2_is_replay\n  val f3_ready = Wire(Bool())\n\n  icache.io.s2_kill := s2_xcpt\n\n  val f2_bpd_resp = bpd.io.resp.f2 // 这里还能拿回resp的f2?那看来是bpd那边会有一个FIFO？\n  val f2_mask = fetchMask(s2_vpc)\n  val f2_redirects = (0 until fetchWidth) map { i =>\n    s2_valid && f2_mask(i) && f2_bpd_resp.preds(i).predicted_pc.valid &&\n    (f2_bpd_resp.preds(i).is_jal ||\n      (f2_bpd_resp.preds(i).is_br && f2_bpd_resp.preds(i).taken))\n  }\n  val f2_redirect_idx = PriorityEncoder(f2_redirects)\n  val f2_targs = f2_bpd_resp.preds.map(_.predicted_pc.bits)\n  val f2_do_redirect = f2_redirects.reduce(_||_) && useBPD.B\n  val f2_predicted_target = Mux(f2_do_redirect,\n                                f2_targs(f2_redirect_idx),\n                                nextFetch(s2_vpc))\n  val f2_predicted_ghist = s2_ghist.update(\n    f2_bpd_resp.preds.map(p => p.is_br && p.predicted_pc.valid).asUInt & f2_mask,\n    f2_bpd_resp.preds(f2_redirect_idx).taken && f2_do_redirect,\n    f2_bpd_resp.preds(f2_redirect_idx).is_br,\n    f2_redirect_idx,\n    f2_do_redirect,\n    s2_vpc,\n    false.B,\n    false.B)\n  \n  // f2_predicted_ghist 设置\n  val f2_correct_f1_ghist = s1_ghist =/= f2_predicted_ghist && enableGHistStallRepair.B\n\n  // 若s2有效且icache的resp无效 或 s2有效且icache的resp有效且f3未准备好\n  when ((s2_valid && !icache.io.resp.valid) ||\n        (s2_valid && icache.io.resp.valid && !f3_ready)) {\n    s0_valid := (!s2_tlb_resp.ae.inst && !s2_tlb_resp.pf.inst) || s2_is_replay || s2_tlb_miss\n    s0_vpc   := s2_vpc\n    s0_is_replay := s2_valid && icache.io.resp.valid // f3未准备好的话，就要让s0_replay?\n    // When this is not a replay (it queried the BPDs, we should use f3 resp in the replaying s1)\n    s0_s1_use_f3_bpd_resp := !s2_is_replay\n    s0_ghist := s2_ghist\n    s0_tsrc  := s2_tsrc\n    f1_clear := true.B   // 置位了f1_clear!\n  } .elsewhen (s2_valid && f3_ready) {\n    when (s1_valid && s1_vpc === f2_predicted_target && !f2_correct_f1_ghist) {\n      // f2_predicted_target 使用当前指令的vpc(现在是s2_vpc)返回的bpd_resp进行预测，s1_vpc是下一条指令的vpc，在此处判断两者是否相等\n      // We trust our prediction of what the global history for the next branch should be\n      s2_ghist := f2_predicted_ghist\n    }\n    when ((s1_valid && (s1_vpc =/= f2_predicted_target || f2_correct_f1_ghist)) || !s1_valid) {\n      f1_clear := true.B\n\n      s0_valid     := !((s2_tlb_resp.ae.inst || s2_tlb_resp.pf.inst) && !s2_is_replay)\n      s0_vpc       := f2_predicted_target\n      s0_is_replay := false.B\n      s0_ghist     := f2_predicted_ghist\n      s2_fsrc      := BSRC_2\n      s0_tsrc      := BSRC_2\n    }\n  }\n  // 把F2阶段的信号转回F1阶段\n  s0_replay_bpd_resp := f2_bpd_resp\n  s0_replay_resp := s2_tlb_resp\n  s0_replay_ppc  := s2_ppc\n```\n\n#### F3\n```scala\n  val f3_clear = WireInit(false.B)\n\n/*  \n    Pipe模式下，整个队列以流水线的状态流动,也就是读入和写出可以在同一个周期内先后完成\n    if (pipe) {\n        when(io.deq.ready) { io.enq.ready := true.B }\n    }\n\n    Flow模式下，输入可以在同一个周期内被输出使用（输出端口直接使用输入）\n    if (flow) {\n        when(io.enq.valid) { io.deq.valid := true.B }\n        when(empty) {\n            io.deq.bits := io.enq.bits\n            do_deq := false.B\n        when(io.deq.ready) { do_enq := false.B }\n        }\n  }\n\n  * \"decoupled\" interface: 'valid' indicates that the producer has\n  * put valid data in 'bits', and 'ready' indicates that the consumer is ready\n  * to accept the data this cycle. 'fire' indicates if IO is both ready and valid\n\n*/\n\n  // IMem Response Queue\n  val f3 = withReset(reset.asBool || f3_clear) {\n    Module(new Queue(new FrontendResp, 1, pipe=true, flow=false)) }\n\n  // Queue up the bpd resp as well, incase f4 backpressures f3\n  // This is \"flow\" because the response (enq) arrives in f3, not f2\n  val f3_bpd_resp = withReset(reset.asBool || f3_clear) {\n    Module(new Queue(new BranchPredictionBundle, 1, pipe=true, flow=true)) }\n\n  val f4_ready = Wire(Bool())\n  f3_ready := f3.io.enq.ready // f3是否ready要看IMem队列入队是否就绪(是否可以接受入队数据)\n  f3.io.enq.valid   := (s2_valid && !f2_clear &&\n    (icache.io.resp.valid || ((s2_tlb_resp.ae.inst || s2_tlb_resp.pf.inst) && !s2_tlb_miss))\n  ) // IMem队列入队是否有效,要看F2阶段的操作是否合法(自然把数据放到正确位置了)\n  \n  //连接s2的数据到IMem队列\n  f3.io.enq.bits.pc := s2_vpc\n  f3.io.enq.bits.data  := Mux(s2_xcpt, 0.U, icache.io.resp.bits.data)\n  f3.io.enq.bits.ghist := s2_ghist\n  f3.io.enq.bits.mask := fetchMask(s2_vpc)\n  f3.io.enq.bits.xcpt := s2_tlb_resp\n  f3.io.enq.bits.fsrc := s2_fsrc\n  f3.io.enq.bits.tsrc := s2_tsrc\n\n  // RAS takes a cycle to read\n  val ras_read_idx = RegInit(0.U(log2Ceil(nRasEntries).W))\n  ras.io.read_idx := ras_read_idx\n  when (f3.io.enq.fire) {\n    ras_read_idx := f3.io.enq.bits.ghist.ras_idx\n    ras.io.read_idx := f3.io.enq.bits.ghist.ras_idx\n  }\n\n  // The BPD resp comes in f3\n  f3_bpd_resp.io.enq.valid := f3.io.deq.valid && RegNext(f3.io.enq.ready) // 上一拍入队就绪(可接受入队数据)，这一拍出队已合法(数据可以出去)\n  f3_bpd_resp.io.enq.bits  := bpd.io.resp.f3\n  when (f3_bpd_resp.io.enq.fire) {\n    bpd.io.f3_fire := true.B\n  }\n\n  // f3两个队列出队要看F4是否就绪 \n  f3.io.deq.ready := f4_ready\n  f3_bpd_resp.io.deq.ready := f4_ready\n\n\n  val f3_imemresp     = f3.io.deq.bits\n  val f3_bank_mask    = bankMask(f3_imemresp.pc)\n  val f3_data         = f3_imemresp.data // 来自Imemresp的一个64bit的数据\n  val f3_aligned_pc   = bankAlign(f3_imemresp.pc)\n  val f3_is_last_bank_in_block = isLastBankInBlock(f3_aligned_pc)\n  val f3_is_rvc       = Wire(Vec(fetchWidth, Bool()))\n  val f3_redirects    = Wire(Vec(fetchWidth, Bool()))\n  val f3_targs        = Wire(Vec(fetchWidth, UInt(vaddrBitsExtended.W)))\n  val f3_cfi_types    = Wire(Vec(fetchWidth, UInt(CFI_SZ.W)))\n  val f3_shadowed_mask = Wire(Vec(fetchWidth, Bool()))\n  val f3_fetch_bundle = Wire(new FetchBundle)\n  val f3_mask         = Wire(Vec(fetchWidth, Bool()))\n  val f3_br_mask      = Wire(Vec(fetchWidth, Bool()))\n  val f3_call_mask    = Wire(Vec(fetchWidth, Bool()))\n  val f3_ret_mask     = Wire(Vec(fetchWidth, Bool()))\n  val f3_npc_plus4_mask = Wire(Vec(fetchWidth, Bool()))\n  val f3_btb_mispredicts = Wire(Vec(fetchWidth, Bool()))\n\n  // f3_fetch_bundle \n  f3_fetch_bundle.mask := f3_mask.asUInt\n  f3_fetch_bundle.br_mask := f3_br_mask.asUInt\n  f3_fetch_bundle.pc := f3_imemresp.pc\n  f3_fetch_bundle.ftq_idx := 0.U // This gets assigned later\n  f3_fetch_bundle.xcpt_pf_if := f3_imemresp.xcpt.pf.inst\n  f3_fetch_bundle.xcpt_ae_if := f3_imemresp.xcpt.ae.inst\n  f3_fetch_bundle.fsrc := f3_imemresp.fsrc\n  f3_fetch_bundle.tsrc := f3_imemresp.tsrc\n  f3_fetch_bundle.shadowed_mask := f3_shadowed_mask\n\n  // Tracks trailing 16b of previous fetch packet\n  val f3_prev_half    = Reg(UInt(16.W))\n  // Tracks if last fetchpacket contained a half-inst\n  val f3_prev_is_half = RegInit(false.B)\n\n  require(fetchWidth >= 4) // Logic gets kind of annoying with fetchWidth = 2\n  def isRVC(inst: UInt) = (inst(1,0) =/= 3.U)\n  var redirect_found = false.B\n  var bank_prev_is_half = f3_prev_is_half\n  var bank_prev_half    = f3_prev_half\n  var last_inst = 0.U(16.W)\n\n  // 下面的硬件都是并行的\n  // 这里主要的困难是需要处理 16b和32b指令混合使用时导致非的对齐情况，并且在fetchBuff中确定好每条指令的起始地址\n  for (b <- 0 until nBanks) { // 分多个Bank处理,每个b对应每个Bank,0th bank对应f3_data(31,0) 1th bank对应f3_data(63,32)\n    val bank_data  = f3_data((b+1)*bankWidth*16-1, b*bankWidth*16) // data of bank from IMem; bankWidth = fetchWidth / nBanks； 一个b计算一次bank_data，取出bandWith个16b；\n    // 实际生成的硬件信号是 wire [63:0] bank_data (after unrolling the loop) ?\n    val bank_mask  = Wire(Vec(bankWidth, Bool()))\n    val bank_insts = Wire(Vec(bankWidth, UInt(32.W))) // insts of bank from IMem，保存bankWidth条, 每条32位\n\n    for (w <- 0 until bankWidth) { // 一个w对应一个16b\n      val i = (b * bankWidth) + w // i定位到在f3_imemresp中当前指令的具体位置，w是每个bank内部的指令索引，i是整个f的指令索引\n\n      val valid = Wire(Bool())\n      val bpu = Module(new BreakpointUnit(nBreakpoints)) // 不知道是啥，看起来像是CheckingPoint?\n      bpu.io.status   := io.cpu.status\n      bpu.io.bp       := io.cpu.bp\n      bpu.io.ea       := DontCare\n      bpu.io.mcontext := io.cpu.mcontext\n      bpu.io.scontext := io.cpu.scontext\n\n      val brsigs = Wire(new BranchDecodeSignals)\n      if (w == 0) {  // 每个Bank的第一条指令\n        val inst0 = Cat(bank_data(15,0), f3_prev_half) // 上一个尾部16b,可能来自同一个IMemResp, f3_prev_half(f3整体的)，bank_prev_half(每个bank自己的)，\n        val inst1 = bank_data(31,0)\n        val exp_inst0 = ExpandRVC(inst0)\n        val exp_inst1 = ExpandRVC(inst1)\n        val pc0 = (f3_aligned_pc + (i << log2Ceil(coreInstBytes)).U - 2.U)\n        val pc1 = (f3_aligned_pc + (i << log2Ceil(coreInstBytes)).U)\n\n        val bpd_decoder0 = Module(new BranchDecode)\n        bpd_decoder0.io.inst := exp_inst0\n        bpd_decoder0.io.pc   := pc0\n        val bpd_decoder1 = Module(new BranchDecode)\n        bpd_decoder1.io.inst := exp_inst1\n        bpd_decoder1.io.pc   := pc1\n\n      when (bank_prev_is_half) { // 处理半条指令 用inst0\n          bank_insts(w)                := inst0\n          f3_fetch_bundle.insts(i)     := inst0\n          f3_fetch_bundle.exp_insts(i) := exp_inst0\n          bpu.io.pc                    := pc0\n          brsigs                       := bpd_decoder0.io.out\n          f3_fetch_bundle.edge_inst(b) := true.B\n          if (b > 0) { // 不是第一个bank\n            val inst0b     = Cat(bank_data(15,0), last_inst) // \n            val exp_inst0b = ExpandRVC(inst0b)\n            val bpd_decoder0b = Module(new BranchDecode)\n            bpd_decoder0b.io.inst := exp_inst0b\n            bpd_decoder0b.io.pc   := pc0\n\n            when (f3_bank_mask(b-1)) { // 且前一个bank没屏蔽\n              bank_insts(w)                := inst0b\n              f3_fetch_bundle.insts(i)     := inst0b\n              f3_fetch_bundle.exp_insts(i) := exp_inst0b\n              brsigs                       := bpd_decoder0b.io.out\n            }\n          }\n        } .otherwise { // 没有wrap around\n          bank_insts(w)                := inst1\n          f3_fetch_bundle.insts(i)     := inst1\n          f3_fetch_bundle.exp_insts(i) := exp_inst1\n          bpu.io.pc                    := pc1\n          brsigs                       := bpd_decoder1.io.out\n          f3_fetch_bundle.edge_inst(b) := false.B\n        }\n        valid := true.B\n      } else { // w != 0\n        val inst = Wire(UInt(32.W))\n        val exp_inst = ExpandRVC(inst)\n        val pc = f3_aligned_pc + (i << log2Ceil(coreInstBytes)).U\n        val bpd_decoder = Module(new BranchDecode) // 用于解码指令是不是br\n        // 插入bpd中\n        bpd_decoder.io.inst := exp_inst\n        bpd_decoder.io.pc   := pc\n\n        bank_insts(w)                := inst\n        f3_fetch_bundle.insts(i)     := inst\n        f3_fetch_bundle.exp_insts(i) := exp_inst\n        bpu.io.pc                    := pc\n        brsigs                       := bpd_decoder.io.out\n        if (w == 1) {\n          // Need special case since 0th instruction may carry over the wrap around\n          inst  := bank_data(47,16) //\n          valid := bank_prev_is_half || !(bank_mask(0) && !isRVC(bank_insts(0))) // 如果有half（也就是前16b用于拼接了）或 0th bank_data被屏蔽了或是RVC\n        } else if (w == bankWidth - 1) { // 已经到最后一个16b了\n          inst  := Cat(0.U(16.W), bank_data(bankWidth*16-1,(bankWidth-1)*16)) // 这就是一个合法的16b指令\n          valid := !((bank_mask(w-1) && !isRVC(bank_insts(w-1))) ||\n            !isRVC(inst)) // 当下的inst是RVC 且 (前一个指令被屏蔽 或前一个指令是RVC)\n        } else {\n          inst  := bank_data(w*16+32-1,w*16)\n          valid := !(bank_mask(w-1) && !isRVC(bank_insts(w-1))) // 前一个指令被屏蔽 或 前一个指令是RVC\n        }\n      }\n\n      f3_is_rvc(i) := isRVC(bank_insts(w))  // 这里会看是不是RVC,即使我们在bank_insts中放置了32bit，在这里也会被发现内部藏了一个16bit\n\n\n      bank_mask(w) := f3.io.deq.valid && f3_imemresp.mask(i) && valid && !redirect_found // 一个w对应一个bank_data 和一个bank_mask\n      f3_mask  (i) := f3.io.deq.valid && f3_imemresp.mask(i) && valid && !redirect_found\n      f3_targs (i) := Mux(brsigs.cfi_type === CFI_JALR,  // JALR指令就走bpd,否则走br\n        f3_bpd_resp.io.deq.bits.preds(i).predicted_pc.bits,\n        brsigs.target)\n\n      // Flush BTB entries for JALs if we mispredict the target\n      f3_btb_mispredicts(i) := (brsigs.cfi_type === CFI_JAL && valid &&\n        f3_bpd_resp.io.deq.bits.preds(i).predicted_pc.valid &&\n        (f3_bpd_resp.io.deq.bits.preds(i).predicted_pc.bits =/= brsigs.target)\n      )\n\n\n      // 判断是不是加4(是不是32bit)\n      f3_npc_plus4_mask(i) := (if (w == 0) { \n        !f3_is_rvc(i) && !bank_prev_is_half\n      } else {\n        !f3_is_rvc(i)\n      })\n      val offset_from_aligned_pc = (\n        (i << 1).U((log2Ceil(icBlockBytes)+1).W) +\n        brsigs.sfb_offset.bits -\n        Mux(bank_prev_is_half && (w == 0).B, 2.U, 0.U)\n      )\n      val lower_mask = Wire(UInt((2*fetchWidth).W))\n      val upper_mask = Wire(UInt((2*fetchWidth).W))\n      lower_mask := UIntToOH(i.U)\n      upper_mask := UIntToOH(offset_from_aligned_pc(log2Ceil(fetchBytes)+1,1)) << Mux(f3_is_last_bank_in_block, bankWidth.U, 0.U)\n\n      f3_fetch_bundle.sfbs(i) := (\n        f3_mask(i) &&\n        brsigs.sfb_offset.valid &&\n        (offset_from_aligned_pc <= Mux(f3_is_last_bank_in_block, (fetchBytes+bankBytes).U,(2*fetchBytes).U))\n      )\n      f3_fetch_bundle.sfb_masks(i)       := ~MaskLower(lower_mask) & ~MaskUpper(upper_mask)\n      f3_fetch_bundle.shadowable_mask(i) := (!(f3_fetch_bundle.xcpt_pf_if || f3_fetch_bundle.xcpt_ae_if || bpu.io.debug_if || bpu.io.xcpt_if) &&\n                                             f3_bank_mask(b) &&\n                                             (brsigs.shadowable || !f3_mask(i)))\n      f3_fetch_bundle.sfb_dests(i)       := offset_from_aligned_pc\n\n      // Redirect if\n      //  1) its a JAL/JALR (unconditional)\n      //  2) the BPD believes this is a branch and says we should take it\n      f3_redirects(i)    := f3_mask(i) && (\n        brsigs.cfi_type === CFI_JAL || brsigs.cfi_type === CFI_JALR ||\n        (brsigs.cfi_type === CFI_BR && f3_bpd_resp.io.deq.bits.preds(i).taken && useBPD.B)\n      )\n\n      f3_br_mask(i)   := f3_mask(i) && brsigs.cfi_type === CFI_BR\n      f3_cfi_types(i) := brsigs.cfi_type\n      f3_call_mask(i) := brsigs.is_call\n      f3_ret_mask(i)  := brsigs.is_ret\n\n      f3_fetch_bundle.bp_debug_if_oh(i) := bpu.io.debug_if\n      f3_fetch_bundle.bp_xcpt_if_oh (i) := bpu.io.xcpt_if\n\n      redirect_found = redirect_found || f3_redirects(i)\n    } // 处理完一行bank后就要更新last_inst\n    last_inst = bank_insts(bankWidth-1)(15,0) // 每个bank中的最后一个指令的最后16位(15,0)\n    bank_prev_is_half = Mux(f3_bank_mask(b),\n      (!(bank_mask(bankWidth-2) && !isRVC(bank_insts(bankWidth-2))) && !isRVC(last_inst)),  \n      bank_prev_is_half)\n        // 怎么样才会是跨边界了的指令呢？ 如果当前bank的掩码为0（根本不使用），那直接继承之前的状态；否则需要查看bank内的情况，(0,0)处被屏蔽掉了或(0,0)是RVC指令，且(0,1)处不是RVC指令\n    bank_prev_half    = Mux(f3_bank_mask(b),\n      last_inst(15,0),\n      bank_prev_half)\n  }\n\n  f3_fetch_bundle.cfi_type      := f3_cfi_types(f3_fetch_bundle.cfi_idx.bits)\n  f3_fetch_bundle.cfi_is_call   := f3_call_mask(f3_fetch_bundle.cfi_idx.bits)\n  f3_fetch_bundle.cfi_is_ret    := f3_ret_mask (f3_fetch_bundle.cfi_idx.bits)\n  f3_fetch_bundle.cfi_npc_plus4 := f3_npc_plus4_mask(f3_fetch_bundle.cfi_idx.bits)\n\n  f3_fetch_bundle.ghist    := f3.io.deq.bits.ghist\n  f3_fetch_bundle.lhist    := f3_bpd_resp.io.deq.bits.lhist\n  f3_fetch_bundle.bpd_meta := f3_bpd_resp.io.deq.bits.meta\n\n  f3_fetch_bundle.end_half.valid := bank_prev_is_half\n  f3_fetch_bundle.end_half.bits  := bank_prev_half\n\n  // 每次f3发射的时候，就把bank的跟踪记录更新到f3整体的跟踪记录上\n  when (f3.io.deq.fire) {\n    f3_prev_is_half := bank_prev_is_half\n    f3_prev_half    := bank_prev_half\n    assert(f3_bpd_resp.io.deq.bits.pc === f3_fetch_bundle.pc)\n  }\n\n  when (f3_clear) {\n    f3_prev_is_half := false.B\n  }\n\n  f3_fetch_bundle.cfi_idx.valid := f3_redirects.reduce(_||_)\n  f3_fetch_bundle.cfi_idx.bits  := PriorityEncoder(f3_redirects)\n\n  f3_fetch_bundle.ras_top := ras.io.read_addr\n  // Redirect earlier stages only if the later stage\n  // can consume this packet\n\n  val f3_predicted_target = Mux(f3_redirects.reduce(_||_),\n    Mux(f3_fetch_bundle.cfi_is_ret && useBPD.B && useRAS.B,\n      ras.io.read_addr,\n      f3_targs(PriorityEncoder(f3_redirects))\n    ),\n    nextFetch(f3_fetch_bundle.pc)\n  )\n\n  f3_fetch_bundle.next_pc       := f3_predicted_target\n  val f3_predicted_ghist = f3_fetch_bundle.ghist.update(\n    f3_fetch_bundle.br_mask,\n    f3_fetch_bundle.cfi_idx.valid,\n    f3_fetch_bundle.br_mask(f3_fetch_bundle.cfi_idx.bits),\n    f3_fetch_bundle.cfi_idx.bits,\n    f3_fetch_bundle.cfi_idx.valid,\n    f3_fetch_bundle.pc,\n    f3_fetch_bundle.cfi_is_call,\n    f3_fetch_bundle.cfi_is_ret\n  )\n\n\n  ras.io.write_valid := false.B\n  ras.io.write_addr  := f3_aligned_pc + (f3_fetch_bundle.cfi_idx.bits << 1) + Mux(\n    f3_fetch_bundle.cfi_npc_plus4, 4.U, 2.U)\n  ras.io.write_idx   := WrapInc(f3_fetch_bundle.ghist.ras_idx, nRasEntries)\n\n\n  val f3_correct_f1_ghist = s1_ghist =/= f3_predicted_ghist && enableGHistStallRepair.B\n  val f3_correct_f2_ghist = s2_ghist =/= f3_predicted_ghist && enableGHistStallRepair.B\n\n  when (f3.io.deq.valid && f4_ready) {\n    when (f3_fetch_bundle.cfi_is_call && f3_fetch_bundle.cfi_idx.valid) {\n      ras.io.write_valid := true.B\n    }\n    when (f3_redirects.reduce(_||_)) {\n      f3_prev_is_half := false.B\n    }\n    when (s2_valid && s2_vpc === f3_predicted_target && !f3_correct_f2_ghist) {\n      f3.io.enq.bits.ghist := f3_predicted_ghist\n    } .elsewhen (!s2_valid && s1_valid && s1_vpc === f3_predicted_target && !f3_correct_f1_ghist) {\n      s2_ghist := f3_predicted_ghist\n    } .elsewhen (( s2_valid &&  (s2_vpc =/= f3_predicted_target || f3_correct_f2_ghist)) ||\n          (!s2_valid &&  s1_valid && (s1_vpc =/= f3_predicted_target || f3_correct_f1_ghist)) ||\n          (!s2_valid && !s1_valid)) {\n      f2_clear := true.B\n      f1_clear := true.B\n\n      s0_valid     := !(f3_fetch_bundle.xcpt_pf_if || f3_fetch_bundle.xcpt_ae_if)\n      s0_vpc       := f3_predicted_target\n      s0_is_replay := false.B\n      s0_ghist     := f3_predicted_ghist\n      s0_tsrc      := BSRC_3\n\n      f3_fetch_bundle.fsrc := BSRC_3\n    }\n  }\n\n  // When f3 finds a btb mispredict, queue up a bpd correction update\n  val f4_btb_corrections = Module(new Queue(new BranchPredictionUpdate, 2))\n  f4_btb_corrections.io.enq.valid := f3.io.deq.fire && f3_btb_mispredicts.reduce(_||_) && enableBTBFastRepair.B\n  f4_btb_corrections.io.enq.bits  := DontCare\n  f4_btb_corrections.io.enq.bits.is_mispredict_update := false.B\n  f4_btb_corrections.io.enq.bits.is_repair_update     := false.B\n  f4_btb_corrections.io.enq.bits.btb_mispredicts      := f3_btb_mispredicts.asUInt\n  f4_btb_corrections.io.enq.bits.pc                   := f3_fetch_bundle.pc\n  f4_btb_corrections.io.enq.bits.ghist                := f3_fetch_bundle.ghist\n  f4_btb_corrections.io.enq.bits.lhist                := f3_fetch_bundle.lhist\n  f4_btb_corrections.io.enq.bits.meta                 := f3_fetch_bundle.bpd_meta\n\n```\n\n在f3阶段有一个重要的工作就是对于来自ICache的Response进行拆解分析，区分出RVC(16bits)指令和普通指令(32bits)并放置到`fetch_bundle`中，方便后续使用，其实现比较复杂难懂，在这里作简要说明。\n![](/images/F3_bank_insts.jpg)\n如上图所示，每个周期，从ICache来的数据`f3_data`为64bits,将其分为2个Banks,并在循环中用二维索引(w,b)进行表示(当然在循环中只能看到最内层的w，外层的b是隐藏的索引)。在`fetch_bundle`中，为了用最少的位置存放所有可能的情况，这里将`fetch_bundle.insts`也按照w,b设置为4项，分别表示以这个位置开头的指令（也就是以`f3_data(0)`,`f3_data(16)`,`f3_data(32)`,`f3_data(48)`开头的指令），而以这些位置开头的指令是否合法，则使用`f3_mask`等信号进行控制。在进行拆解的过程中，可能会使用前面“残留的”指令与当前部分指令进行拼接，生成对应指令，具体过程如上图标注。\n\n#### F4 & F5\n**TO DO**\n\n#### 关键信号跟踪\n##### `sx_valid`\n`sx_valid`信号就是每个阶段stage x的使能信号，只有使能信号为`true.B`时，流水段才可能流动(当然还可能要看其他信号，如`fx_clear`)，`s0_valid`信号是一个WireInt类型信号，同时`s0_valid`信号随着流水线流动，逐步赋值给`sx_valid`这些Reg类型信号，进而使能对应阶段及其内部的部件\n1. `s0_valid`作为最初的使能信号，在复位后变为`true.B`，在F0阶段使能ICache和BPD这两个部件；在如下情形下会被置为`false.B`：\n    - F1阶段：当前指令是ae或pf(通过s1_tlb_resp判断)\n    - F2阶段：\n        - ICache没准备好或F3未准备好：当前指令的TLB命中了，不需要replay，且是ae或pf(通过s2_tlb_miss,s2_is_replay,s2_tlb_resp判断)\n        - F3已准备好，F2未使能或F2已使能但下条指令和当前指令预测不符合：当前指令不需要replay,且是ae或pf\n2. `s1_valid`由`s0_valid`在新时钟周期到来时更新,在F1阶段中使能TLB部件；\n3. `s2_valid`由`s1_valid`在新时钟周期到来时更新\n##### `sx_is_replay`\n`sx_is_replay`信号控制部件进行重复执行操作，如某条指令若在F2阶段发现F3阶段未准备好，其会重新转回F1阶段进行执行。\n1. `s0_is_replay`是最初的replay信号，复位后变为`false.B`，在F2阶段中，若F3未准备好，则会被置为`true.B`\n2. `s1_is_replay`由`s0_is_replay`在新时钟周期到来时更新，为`true.B`时：\n    - F1阶段：阻塞对tlb请求的使能，选择实际来自F2阶段传入的`tlb_resp`作为`tlb_resp`，选择F2阶段传入的`tlb_ppc`作为`tlb_ppc`\n##### `fx_clear`\n`fx_clear`信号控制是否刷新流水段\n1. `f1_clear`在F1阶段阻塞对tlb请求的使能，阻塞`s1_valid`向`s2_valid`传播，使能对Icache的s1_kill信号。在如下情况下会被置为`true.B`\n    - F2阶段：ICache或F3未准备好；ICache和F3已准备好，但下条指令和当前指令预测不符合\n    - F3阶段：\n    - F5阶段：\n\n","tags":["Code Reading"],"categories":["Computer Architecture","RISCV-BOOM"]},{"title":"RISCV-BOOM(1)","url":"/2024/04/07/RISCV-BOOM-1/","content":"# RISCV-BOOM Pipeline \n## 流水段划分\n![](/images/boom-pipeline.svg)\nRISCV-BOOM概念上划分为`Fetch`, `Decode`, `Register Rename`, `Dispatch`, `Issue`, `Register Read`, `Execute`, `Memory`, `Writeback` 和 `Commit`阶段;但在其实现时只划分为`Fetch`, `Decode&Rename`, `Raname&Dispatch`, `Issue&Register Read`, `Execute`, `Memory`和`Writeback`。\n\n1. Fetch：把指令从指令存储器（L1ICache及下层Cache）中取出并放入`Fetch Buffer`。此阶段同时发生分支预测，每条指令都附有一个分支标记，用于标记推测分支\n2. Decode: 从`Fetch Buffer`中提取指令并生成`Micro-Op(UOP)`\n3. Rename: 将逻辑寄存器重命名为物理寄存器\n4. Dispatch: 把`UOP`分派到一组`Issue Queue(IQ)`中\n5. Issue: 当`IQ`中的`UOP`的所有操作数准备就绪后进行发射。**此处是流水段无序部分的开始**\n6. Register Read: 发射的`UOP`从统一的物理寄存器中（或旁路网络中）读取操作数\n7. Execute: `UOP`进入功能部件执行其功能\n8. Memory: `Load Address Queue(LAQ)`, `Store Address Queue(SAQ)`, `Store Data Queue(SDQ)`。`Load`指令会在计算出地址并放入`LAQ`时就访问内存，但`Store`指令要到`Commit`阶段才会访问内存\n9. Writeback: `ALU`和访存指令结果写回物理寄存器堆\n10. Commit: 当`ROB`首指令空闲时进行指令提交，对于存储指令(Store)，此时`ROB`向`SAQ/SDQ`发出信号，使其进行内存写入\n## 整体架构图\n![](/images/boom-pipeline-detailed.webp)\n\n","tags":["Code Reading"],"categories":["Computer Architecture","RISCV-BOOM"]},{"title":"Cache Coherence Instances","url":"/2024/04/02/Cache-Coherence-Instances/","content":"\n# SGI ORIGIN\n\n![](/images/SGIOrigin.png)\n\n\n专为大规模高可扩展系统设计\n\n**特点**\n- 动态选择`coaese bit vector`或`limited pointer`来表示目录中的`share list`，以节省空间\n- 由于不要求互联网络的强有序性，需要考虑额外的一致性消息竞争问题\n- 使用不表示占用属性的`E`状态，允许`E`状态和`S`状态的静默换出，这将导致`GetS`的回复过程变得更复杂\n- 使用`Upgrade`一致性请求将`S`状态升格为`E`状态，不需要请求数据\n- 将三种网络（`request`, `forwarded request`和`response`）减少为两种（`request` 和 `response`）。由此导致的死锁情况通过额外的`Backoff`消息来处理\n\n# Coherent HyperTransport\n\n![](/images/CoherenceHT.png)\n\n为中小规模扩展系统设计,实际上目录到核心使用广播传递（forwarded）消息，核心到目录使用点对点链路\n\n**特点**\n- 采用$Dir_0B$目录协议，是一种`null directory cache`设计，目录不储存任何缓存块，所有发送到目录的请求都会Miss，然后通过广播被目录前递到所有缓存块 \n- 不需要全序的一致性请求，对于互联网络而言具有更大的扩展性\n- 事实上比广播一致性协议更消耗带宽，因为所有`forward`操作都将产生`response`\n\n# Hypertransport Assist\n\n**特点**\n- 采用`inclusive directory cache`设计，只缓存归属于自己片内的，在上层缓存中有效的块，没有DRAM目录\n- 在目录缓存中的Miss意味着当前请求的块不存在于该片的任何一个地方\n- 当目录缓存满还需要加入新项时，利用`Recall`操作进行换出\n- 用更少的标志位来表示`share list`，只区分没有`sharer`，一个`sharer`，两个及以上`sharer`这三种状态\n- 要求目录项数量是缓存块的两倍，但不采用显式`PutS`请求\n- 目录缓存共享LLC\n\n# Intel QPI\n**特点**\n- 支持`MESIF`五种状态，`F`状态是未被修改的只读状态。与`S`状态不一样的是，`F`状态可以向一致性请求返回数据;与`O`状态不一样的是，`F`状态是未修改的，所以可以进行静默替换\n- `F`状态使得核心可以**直接**从缓存中获取只读数据，而不是从目录的回复中获取\n- 提供两种协议模式，`home snoop`和`source snoop`：\n    - `Home Snoop`模式用于高可扩展情形。此时目录作为协议中的串行化节点，解决消息竞争问题\n    - `Source Snoop`模式用于低时延情形。此时利用广播向所有节点请求块，代价是降低其可扩展性。虽然相较于`Home Snoop`占用了更多的带宽，但其一致性事务的平均处理时间大大降低了\n","tags":["Direcotry Protocol"],"categories":["Computer Architecture","Cache Coherence"]}]